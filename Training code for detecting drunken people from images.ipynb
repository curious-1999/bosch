{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working!!!\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('D:\\setups\\drunkImagesWebp')\n",
    "\n",
    "count = 1\n",
    "for file in glob.glob('*webp'):\n",
    "\n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    UL = img[:h//2, :w//2]\n",
    "    UR = img[:h//2, w//2:]\n",
    "    LL = img[h//2:, :w//2]\n",
    "    LR = img[h//2:, w//2:]\n",
    "    f1=\"D:/setups/xyz/UL\"+str(count)+\".png\"\n",
    "    f2=\"D:/setups/xyz/UR\"+str(count)+\".png\"\n",
    "    f3=\"D:/setups/xyz/LL\"+str(count)+\".png\"\n",
    "    f4=\"D:/setups/xyz/LR\"+str(count)+\".png\"\n",
    "    cv2.imwrite(f1, UL)\n",
    "    cv2.imwrite(f2, UR)\n",
    "    cv2.imwrite(f3, LL)\n",
    "    cv2.imwrite(f4, LR)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working !!\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from pathlib import Path\n",
    "face_cascade = cv2.CascadeClassifier('F:/haarcascade_frontalface_default.xml')\n",
    "\n",
    "min_w = sys.maxsize\n",
    "min_h = sys.maxsize\n",
    "\n",
    "width = []\n",
    "height = []\n",
    "\n",
    "os.chdir('F:\\drunkimagesinpng')\n",
    "\n",
    "for file in sorted(glob.glob('*.png')):\n",
    "    print(file)\n",
    "\n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.01, 10)\n",
    "\n",
    "    if not len(faces):\n",
    "        open_file = open('F:/error.txt', 'w')\n",
    "        open_file.write('{}\\n'.format(file))\n",
    "        open_file.close()\n",
    "\n",
    "        continue\n",
    "\n",
    "    x, y, w, h = faces[0]\n",
    "    width += [w]\n",
    "    height += [h]\n",
    "\n",
    "    if faces[0, 3] < 105 or faces[0, 2] < 105:\n",
    "        dir = 'F:\\min_frontal_face'\n",
    "\n",
    "    else:\n",
    "        dir = 'F:\\har_frontal_face'\n",
    "\n",
    "        if w < min_w:\n",
    "            min_w = w\n",
    "\n",
    "        if h < min_h:\n",
    "            min_h = h\n",
    "\n",
    "    face = img[y:y + h, x:x + w]\n",
    "\n",
    "    cv2.imwrite(os.path.join(dir,file), face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working!!!\n",
    "os.chdir('F:\\har_frontal_face')\n",
    "count=0\n",
    "for file in glob.glob('*.png'):\n",
    "    count+=1\n",
    "    print(file)\n",
    "\n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    img_shape = img.shape\n",
    "\n",
    "    img = cv2.resize(img, (0, 0), fx=min_w / img_shape[1], fy=min_h / img_shape[0], interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    cv2.imwrite(file,img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imgaug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77f5d289ea2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#working!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maugmenters\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0miaa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imgaug'"
     ]
    }
   ],
   "source": [
    "#working!!\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import cv2\n",
    "import itertools\n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n",
    "import random\n",
    "\n",
    "\n",
    "os.chdir('D:\\setups\\har_frontal_face1')\n",
    "meta = {'noop': iaa.Noop(), 'shuffle': iaa.ChannelShuffle(p=1.0)}\n",
    "blur = {'GBlur': iaa.GaussianBlur(sigma=1.00),\n",
    "        'ABlur': iaa.AverageBlur(k=3), 'MBlur': iaa.MedianBlur(k=3),\n",
    "        'BBlur': iaa.BilateralBlur(sigma_color=250, sigma_space=250, d=5)}\n",
    "contrast = {'GContrast-': iaa.GammaContrast(gamma=0.81),\n",
    "            'GContrast+': iaa.GammaContrast(gamma=1.44), 'SContrast': iaa.SigmoidContrast(cutoff=0.5, gain=10)}\n",
    "flip = {'flipLR': iaa.Fliplr(p=1.0)}\n",
    "color = {'ATHAS-': iaa.AddToHueAndSaturation(value=-45), 'ATHAS+': iaa.AddToHueAndSaturation(value=45),\n",
    "         'Gray': iaa.Grayscale(alpha=0.2)}\n",
    "geometric = {'PAffine': iaa.PiecewiseAffine(scale=0.030), 'PTrans-': iaa.PerspectiveTransform(scale=0.50),\n",
    "             'PTrans': iaa.PerspectiveTransform(scale=0.75), 'PTrans+': iaa.PerspectiveTransform(scale=1.0)}\n",
    "size = {'zoomOutU': iaa.PadToFixedSize(height=102, width=102, position='uniform'),\n",
    "        'zoomOutN': iaa.PadToFixedSize(height=102, width=102, position='normal'),\n",
    "        'zoomInU': iaa.PadToFixedSize(height=38, width=38, position='uniform'),\n",
    "        'zoomInN': iaa.PadToFixedSize(height=38, width=38, position='normal')}\n",
    "arithmetic = {'add-45': iaa.Add(value=-45),\n",
    "              'addp-': iaa.Add(value=(-35, -15), per_channel=True), 'addp+': iaa.Add(value=(15, 35), per_channel=True),\n",
    "              'addGN': iaa.AdditiveGaussianNoise(scale=0.10 * 255),\n",
    "              'addGNp': iaa.AdditiveGaussianNoise(scale=0.10 * 255, per_channel=True)}\n",
    "effects = {**meta, **blur, **contrast, **flip, **color,**geometric,**size,**arithmetic}\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(2):\n",
    "    # combs = [_ for _ in itertools.combinations(effects, i + 1)]\n",
    "    combs = list(itertools.combinations(effects.keys(), i + 1))\n",
    "\n",
    "    # Shuffles the array in-place\n",
    "    # combs = random.shuffle(combs)\n",
    "    combs = random.sample(combs, len(combs))\n",
    "\n",
    "    print(len(combs))\n",
    "    for aug in combs:\n",
    "\n",
    "        if count > 50000:\n",
    "            break\n",
    "\n",
    "        aug_effects = list(map(lambda x: effects[x], aug))\n",
    "        # print(str(aug_effects))\n",
    "\n",
    "        if not len(aug_effects) - 1:\n",
    "            seq = aug_effects[0].to_deterministic()\n",
    "\n",
    "        else:\n",
    "            seq = iaa.Sequential(aug_effects).to_deterministic()\n",
    "\n",
    "        for file in glob.glob('*.png'):\n",
    "            if len(file) > 17:\n",
    "                continue\n",
    "\n",
    "            print(i + 1, file, count)\n",
    "\n",
    "            img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "            aug_img = seq.augment_image(img)\n",
    "\n",
    "            ext = reduce((lambda x, y: str(x) + '_' + str(y)), aug)\n",
    "\n",
    "            cv2.imwrite(file.replace('.png', '_{}.png'.format(ext)), aug_img)\n",
    "\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working!!\n",
    "from os import rename, listdir, chdir, mkdir\n",
    "from shutil import move, copy\n",
    "import random\n",
    "\n",
    "\n",
    "# need to update for different filetypes\n",
    "def rename_files():\n",
    "    chdir('F:\\har_frontal_face1')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for filename in glob.glob('*.png'):\n",
    "        \n",
    "        if 'UL' in filename:\n",
    "            rename(filename, '0_'+ str(count)+ '.png')\n",
    "            count = count + 1\n",
    "\n",
    "        elif 'LL' in filename:\n",
    "            rename(filename, '1_' +str(count) + '.png')\n",
    "            count = count + 1\n",
    "\n",
    "        elif 'UR' in filename:\n",
    "            rename(filename, '2_' +str(count) + '.png')\n",
    "            count = count + 1\n",
    "\n",
    "        elif 'LR' in filename:\n",
    "            rename(filename, '3_' + str(count) + '.png')\n",
    "            count = count + 1\n",
    "\n",
    "    print(str(count) + ' files converted.')\n",
    "\n",
    "\n",
    "# move files from the new directory to either positive or negative\n",
    "def move_files():\n",
    "    chdir('F:\\har_frontal_face1')\n",
    "\n",
    "    for filename in glob.glob('*.png'):\n",
    "        # 0 or 1 glasses of wine => sober\n",
    "        if filename.startswith('0') or filename.startswith('2'):\n",
    "            move('./' + filename, '../negatives/' + filename)\n",
    "        # else 2 or 3 glasses of wine => drunk\n",
    "        else:\n",
    "            move('./' + filename, '../positives/' + filename)\n",
    "            \n",
    "\n",
    "directory='D:\\setups\\har_frontal_face1'\n",
    "rename_files()\n",
    "move_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading positive image number  0\n",
      "Reading positive image number  1000\n",
      "Reading positive image number  2000\n",
      "Reading positive image number  3000\n",
      "Reading positive image number  4000\n",
      "Reading positive image number  5000\n",
      "Reading positive image number  6000\n",
      "Reading positive image number  7000\n",
      "Reading negative image number  0\n",
      "Reading negative image number  1000\n",
      "Reading negative image number  2000\n",
      "Reading negative image number  3000\n",
      "Reading negative image number  4000\n",
      "Reading negative image number  5000\n",
      "Reading negative image number  6000\n",
      "Reading negative image number  7000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 106, 106, 8)       224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 53, 53, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 53, 53, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 53, 53, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2890      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 7,784\n",
      "Trainable params: 7,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 11200 samples, validate on 4800 samples\n",
      "Epoch 1/15\n",
      "11200/11200 [==============================] - 87s 8ms/step - loss: 0.6425 - acc: 0.6223 - val_loss: 0.5557 - val_acc: 0.7548\n",
      "Epoch 2/15\n",
      "11200/11200 [==============================] - 76s 7ms/step - loss: 0.4349 - acc: 0.8027 - val_loss: 0.3408 - val_acc: 0.8810\n",
      "Epoch 3/15\n",
      "11200/11200 [==============================] - 76s 7ms/step - loss: 0.2912 - acc: 0.8743 - val_loss: 0.2698 - val_acc: 0.8935\n",
      "Epoch 4/15\n",
      "11200/11200 [==============================] - 79s 7ms/step - loss: 0.2220 - acc: 0.9031 - val_loss: 0.1836 - val_acc: 0.9373\n",
      "Epoch 5/15\n",
      "11200/11200 [==============================] - 86s 8ms/step - loss: 0.1753 - acc: 0.9253 - val_loss: 0.1564 - val_acc: 0.9442\n",
      "Epoch 6/15\n",
      "11200/11200 [==============================] - 79s 7ms/step - loss: 0.1480 - acc: 0.9374 - val_loss: 0.1248 - val_acc: 0.9500\n",
      "Epoch 7/15\n",
      "11200/11200 [==============================] - 81s 7ms/step - loss: 0.1329 - acc: 0.9453 - val_loss: 0.1494 - val_acc: 0.9450\n",
      "Epoch 8/15\n",
      "11200/11200 [==============================] - 78s 7ms/step - loss: 0.1188 - acc: 0.9543 - val_loss: 0.1132 - val_acc: 0.9610\n",
      "Epoch 9/15\n",
      "11200/11200 [==============================] - 77s 7ms/step - loss: 0.1006 - acc: 0.9597 - val_loss: 0.0875 - val_acc: 0.9623\n",
      "Epoch 10/15\n",
      "11200/11200 [==============================] - 75s 7ms/step - loss: 0.0981 - acc: 0.9607 - val_loss: 0.0964 - val_acc: 0.9665\n",
      "Epoch 11/15\n",
      "11200/11200 [==============================] - 75s 7ms/step - loss: 0.0857 - acc: 0.9667 - val_loss: 0.0800 - val_acc: 0.9740\n",
      "Epoch 12/15\n",
      "11200/11200 [==============================] - 76s 7ms/step - loss: 0.0769 - acc: 0.9706 - val_loss: 0.0770 - val_acc: 0.9706\n",
      "Epoch 13/15\n",
      "11200/11200 [==============================] - 75s 7ms/step - loss: 0.0734 - acc: 0.9721 - val_loss: 0.0669 - val_acc: 0.9785\n",
      "Epoch 14/15\n",
      "11200/11200 [==============================] - 76s 7ms/step - loss: 0.0675 - acc: 0.9749 - val_loss: 0.0681 - val_acc: 0.9773\n",
      "Epoch 15/15\n",
      "11200/11200 [==============================] - 76s 7ms/step - loss: 0.0596 - acc: 0.9770 - val_loss: 0.0810 - val_acc: 0.9663\n",
      "Test loss:  0.08103869587182999\n",
      "Test accuracy:  0.96625\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import optimizers\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "epochs = 15\n",
    "log_filepath = 'D:\\setups\\deepKerasLog'\n",
    "\n",
    "nCategorySamples = 8000\n",
    "positiveSamples = glob.glob('E:\\p1\\positives/*')[0:nCategorySamples]\n",
    "negativeSamples = glob.glob('E:/n1/negatives/*')[0:nCategorySamples]\n",
    "\n",
    "nImageRows = 106\n",
    "nImageCols = 106\n",
    "nChannels = 3\n",
    "\n",
    "negativeSamples = random.sample(negativeSamples, len(positiveSamples))\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(positiveSamples)):\n",
    "    X_train.append(resize(io.imread(positiveSamples[i]), (nImageRows, nImageCols)))\n",
    "    Y_train.append(1)\n",
    "    if i % 1000 == 0:\n",
    "        print('Reading positive image number ', i)\n",
    "for i in range(len(negativeSamples)):\n",
    "    X_train.append(resize(io.imread(negativeSamples[i]), (nImageRows, nImageCols)))\n",
    "    Y_train.append(0)\n",
    "    if i % 1000 == 0:\n",
    "        print('Reading negative image number ', i)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.30, random_state=42)\n",
    "\n",
    "mean  = X_train.mean(axis=0).mean(axis=0).mean(axis=0)\n",
    "#std   = X_train.std(axis=0).mean(axis=0).mean(axis=0)\n",
    "mean = np.array([0.5,0.5,0.5])\n",
    "std = np.array([1,1,1])\n",
    "X_train = X_train.astype('float')\n",
    "X_test = X_test.astype('float')\n",
    "for i in range(3):\n",
    "    X_train[:,:,:,i] = (X_train[:,:,:,i]- mean[i]) / std[i]\n",
    "    X_test[:,:,:,i] = (X_test[:,:,:,i]- mean[i]) / std[i]\n",
    "\n",
    "num_iterations = int(len(X_train)/batch_size) + 1\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)\n",
    "\n",
    "modelInputShape = (nImageRows, nImageCols, nChannels)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8,kernel_size=(3,3), activation='relu', strides=(1,1), padding='same', input_shape=modelInputShape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(16,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(16,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(Conv2D(8,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "#model.add(Conv2D(8,kernel_size=(3,3), padding='same', activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=.001, momentum=0.9, decay=0.000005, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "tensorBoardCallback = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
    "callbacks = [tensorBoardCallback]\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test,Y_test),shuffle=True)\n",
    "score=model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save(\"D:\\model2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 284, 3)\n",
      "(106, 106, 3)\n",
      "[[1.5364602e-04 9.9984634e-01]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "model=load_model('D:\\model4.h5')\n",
    "img_path='D:\\setups\\cv.jpg'\n",
    "x=cv2.imread(img_path)\n",
    "print(x.shape)\n",
    "r1=106/x.shape[0]\n",
    "r2=106/x.shape[1]\n",
    "\n",
    "cropped = cv2.resize(x, (0,0), fx=r2, fy=r1) \n",
    "print(cropped.shape)\n",
    "y=np.expand_dims(cropped,axis=0)\n",
    "\n",
    "p=model.predict(y)\n",
    "print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
